# rag/vectordb.py
"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 MÃ³dulo: VectorDB (Etapa 3 del pipeline RAG)
 Autor: Ã“scar Centeno Mora
 DescripciÃ³n:
     Este mÃ³dulo construye, administra y prueba una base vectorial (Chroma)
     a partir de los fragmentos de texto procesados (chunks.jsonl).

 Objetivos:
     1. Convertir los fragmentos en objetos Document de LangChain.
     2. Crear embeddings consistentes (mismo modelo para indexar y consultar).
     3. Persistir los vectores en un Ã­ndice Chroma reutilizable.
     4. Permitir pruebas rÃ¡pidas de bÃºsqueda por similitud.

 CaracterÃ­sticas:
     - Evita dependencias frÃ¡giles (usa langchain_community).
     - MultilingÃ¼e (soporta espaÃ±ol, inglÃ©s y otros).
     - Compatibilidad total con el resto del pipeline RAG.
     - Incluye mÃ©tricas estadÃ­sticas para anÃ¡lisis de calidad de los chunks.

 Ejemplos de uso:
     # ConstrucciÃ³n del Ã­ndice
     python -m rag.vectordb --in data/chunks.jsonl --db chroma_db \
         --collection trips_rag --rebuild --stats

     # Consulta de prueba
     python -m rag.vectordb --db chroma_db --collection trips_rag \
         --test "AprazÃ­vel 16 de mayo Brasil" --k 5

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

# â”€â”€ LibrerÃ­as base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import json
import argparse
import warnings
from pathlib import Path
from typing import List, Dict, Any

# Silencia warnings y deprecaciones visuales
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# â”€â”€ LangChain / Chroma / Embeddings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain_chroma import Chroma

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£  CONFIGURACIÃ“N DEL MODELO DE EMBEDDINGS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_embeddings() -> HuggingFaceEmbeddings:
    """
    Construye un modelo de embeddings estable y multilingÃ¼e.

    Modelo usado:
        - "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
        - Funciona bien en CPU (sin requerir GPU).
        - Soporta normalizaciÃ³n L2 (para evitar sesgos por magnitud).

    Retorna:
        HuggingFaceEmbeddings listo para usar en Chroma.
    """
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£  CARGA Y CONVERSIÃ“N DE LOS CHUNKS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_jsonl(p: Path) -> List[Dict[str, Any]]:
    """
    Lee un archivo JSONL (una lÃ­nea = un JSON).
    Cada lÃ­nea contiene: { "id": int, "text": str, "metadata": {...} }
    """
    return [json.loads(line) for line in p.read_text(encoding="utf-8").splitlines()]

def to_documents(items: List[Dict[str, Any]]) -> List[Document]:
    """
    Convierte una lista de diccionarios a objetos Document de LangChain.

    - AÃ±ade metadatos Ãºtiles para trazabilidad:
        â€¢ source: archivo original
        â€¢ chunk_id: identificador numÃ©rico
    """
    docs = []
    for it in items:
        meta = it.get("metadata", {}) or {}
        meta["source"] = meta.get("source", "chunks.txt")
        meta["chunk_id"] = it.get("id")
        docs.append(Document(page_content=it["text"], metadata=meta))
    return docs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£  CONSTRUCCIÃ“N DEL ÃNDICE VECTORIAL (Chroma)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_chroma(db_dir: Path, collection: str, docs: List[Document]) -> Chroma:
    """
    Construye (o reconstruye) un Ã­ndice Chroma persistente.

    ParÃ¡metros:
        db_dir: ruta al directorio de la base vectorial (ej. chroma_db)
        collection: nombre de la colecciÃ³n
        docs: lista de documentos para indexar
    """
    emb = build_embeddings()

    # InicializaciÃ³n del Ã­ndice (vacÃ­o)
    vs = Chroma(
        persist_directory=str(db_dir),
        collection_name=collection,
        embedding_function=emb
    )

    # Limpieza preventiva (evita colecciones duplicadas)
    try:
        vs.delete_collection()
    except Exception:
        pass

    # ReconstrucciÃ³n e inserciÃ³n
    vs = Chroma(
        persist_directory=str(db_dir),
        collection_name=collection,
        embedding_function=emb
    )
    vs.add_documents(docs)

    # Persistencia local (en disco)
    try:
        vs.persist()
    except Exception:
        pass

    return vs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£  CARGA DEL VECTORSTORE EXISTENTE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_vs(db_dir: Path, collection: str) -> Chroma:
    """
    Carga una colecciÃ³n Chroma previamente construida.
    """
    emb = build_embeddings()
    return Chroma(
        persist_directory=str(db_dir),
        collection_name=collection,
        embedding_function=emb,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5ï¸âƒ£  CLI PRINCIPAL: construcciÃ³n, estadÃ­sticas y pruebas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    ap = argparse.ArgumentParser(description="Gestor de Ã­ndice vectorial Chroma (Etapa 3)")
    ap.add_argument("--in", dest="inp", help="Ruta al JSONL de chunks (ej. data/chunks.jsonl)")
    ap.add_argument("--db", default="chroma_db", help="Directorio de la base vectorial")
    ap.add_argument("--collection", default="trips_rag", help="Nombre de la colecciÃ³n")
    ap.add_argument("--rebuild", action="store_true", help="Reconstruye el Ã­ndice desde cero")
    ap.add_argument("--stats", action="store_true", help="Muestra estadÃ­sticas de los chunks")
    ap.add_argument("--test", help="Consulta de prueba (opcional)")
    ap.add_argument("--k", type=int, default=5, help="Cantidad de resultados en test")
    args = ap.parse_args()

    db_dir = Path(args.db)

    # â”€â”€ ConstrucciÃ³n del Ã­ndice â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.rebuild:
        assert args.inp, "--in es requerido con --rebuild"
        items = read_jsonl(Path(args.inp))
        docs = to_documents(items)

        # MÃ©tricas descriptivas bÃ¡sicas
        if args.stats:
            lens = [len(d.page_content) for d in docs]
            print(f"ğŸ“¦ Documentos a indexar: {len(docs)}")
            if lens:
                print(
                    f"ğŸ”¤ len chars â†’ min {min(lens)}, "
                    f"median {sorted(lens)[len(lens)//2]}, "
                    f"mean {sum(lens)/len(lens):.1f}, "
                    f"max {max(lens)}"
                )

        _ = build_chroma(db_dir, args.collection, docs)
        print(f"âœ… Ãndice creado y persistido en '{args.db}' (colecciÃ³n: {args.collection})")

    # â”€â”€ Test de similitud (QA manual rÃ¡pido) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.test:
        vs = get_vs(db_dir, args.collection)
        print(f"\nğŸ” TEST QUERY (k={args.k}): {args.test}\n")

        try:
            docs_scores = vs.similarity_search_with_relevance_scores(args.test, k=args.k)
            for i, (d, s) in enumerate(docs_scores, 1):
                print(
                    f"[{i}] score={s:.4f} | "
                    f"source={d.metadata.get('source')} | chunk_id={d.metadata.get('chunk_id')}\n"
                    f"{d.page_content[:260]}...\n"
                )
        except Exception:
            # Compatibilidad con versiones anteriores de LangChain
            docs_scores = vs.similarity_search_with_score(args.test, k=args.k)
            for i, (d, dist) in enumerate(docs_scores, 1):
                rel = 1.0 / (1.0 + float(dist))
                print(
                    f"[{i}] scoreâ‰ˆ{rel:.4f} | "
                    f"source={d.metadata.get('source')} | chunk_id={d.metadata.get('chunk_id')}\n"
                    f"{d.page_content[:260]}...\n"
                )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()